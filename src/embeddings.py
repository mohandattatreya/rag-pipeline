from sentence_transformers import SentenceTransformer
from typing import List, Optional
import numpy as np
import logging
import torch

from src.config import settings

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Globals --- #
_model: Optional[SentenceTransformer] = None
_model_name: Optional[str] = None

def _get_device() -> str:
    """Determines the optimal device (CPU, CUDA, MPS) for running the model."""
    if torch.cuda.is_available():
        return "cuda"
    elif torch.backends.mps.is_available():
        # Check if MPS is built and available (for Apple Silicon)
        # Note: MPS support might vary depending on torch/transformer versions
        # Also check if MPS is usable
        if torch.backends.mps.is_built():
             return "mps"
        else:
             logger.warning("MPS backend is available but not built. Falling back to CPU.")
             return "cpu"
    else:
        return "cpu"

DEVICE = _get_device()

def load_embedding_model() -> SentenceTransformer:
    """Loads the Sentence Transformer model specified in config (singleton pattern)."""
    global _model, _model_name
    model_name_from_config = settings.embedding.model_name

    if _model is None or _model_name != model_name_from_config:
        logger.info(f"Loading embedding model: {model_name_from_config} onto device: {DEVICE}")
        try:
            _model = SentenceTransformer(model_name_from_config, device=DEVICE)
            _model_name = model_name_from_config
            logger.info(f"Model '{_model_name}' loaded successfully.")
        except Exception as e:
            logger.exception(f"Failed to load Sentence Transformer model '{model_name_from_config}': {e}")
            raise
    # else:
    #     logger.debug(f"Using cached model: {_model_name}")
    return _model

def generate_embedding(text: str) -> np.ndarray:
    """Generates a vector embedding for a single piece of text."""
    model = load_embedding_model()
    try:
        # The model's encode function returns a numpy array directly
        embedding = model.encode(text, convert_to_numpy=True)
        return embedding
    except Exception as e:
        logger.exception(f"Error generating embedding for text: '{text[:50]}...': {e}")
        raise

def generate_embeddings_batch(texts: List[str], batch_size: int = 32) -> List[np.ndarray]:
    """Generates vector embeddings for a batch of texts."""
    model = load_embedding_model()
    try:
        # Encode in batches for potentially better performance
        embeddings = model.encode(texts, batch_size=batch_size, convert_to_numpy=True)
        logger.info(f"Generated embeddings for a batch of {len(texts)} texts.")
        return list(embeddings) # Return as a list of numpy arrays
    except Exception as e:
        logger.exception(f"Error generating embeddings for batch (size {len(texts)}): {e}")
        raise

def get_embedding_dimension() -> int:
    """Returns the dimension of the embeddings generated by the loaded model."""
    model = load_embedding_model()
    dimension = model.get_sentence_embedding_dimension()
    if dimension is None:
        # This case should ideally not happen if the model loaded correctly
        logger.error("Could not determine embedding dimension from the loaded model.")
        raise ValueError("Embedding dimension could not be determined.")
    return dimension

# Example usage
if __name__ == "__main__":
    logger.info("--- Testing Embedding Generation ---")

    # 1. Load model and get dimension
    try:
        dim = get_embedding_dimension()
        logger.info(f"Model loaded. Embedding dimension: {dim}")
    except Exception as e:
        logger.error(f"Failed to load model or get dimension: {e}")
        exit(1)

    # 2. Generate single embedding
    test_text_single = "This is a test sentence."
    try:
        emb_single = generate_embedding(test_text_single)
        logger.info(f"Generated embedding for single text. Shape: {emb_single.shape}, Type: {type(emb_single)}")
        # print(f"Embedding (first 5 dims): {emb_single[:5]}")
    except Exception as e:
        logger.error(f"Failed to generate single embedding: {e}")

    # 3. Generate batch embeddings
    test_texts_batch = [
        "Sentence one for batch processing.",
        "Another sentence to embed.",
        "Batching can improve efficiency."
    ]
    try:
        embs_batch = generate_embeddings_batch(test_texts_batch)
        logger.info(f"Generated embeddings for batch. Number: {len(embs_batch)}, Shape[0]: {embs_batch[0].shape}, Type[0]: {type(embs_batch[0])}")
    except Exception as e:
        logger.error(f"Failed to generate batch embeddings: {e}")

    logger.info("--- Embedding Generation Test Complete ---") 